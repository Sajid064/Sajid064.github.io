---
title: "Fired_from_NLP at CheckThat! 2024: Estimating the Check-Worthiness of Tweets Using a Fine-tuned Transformer-based Approach"
collection: publications
permalink: /publication/5
excerpt: ''
date: 2024-08-09
volume: 'CLEF 2024: Conference and Labs of the Evaluation Forum'
address: 'Grenoble, France'
paperurl: 'https://ceur-ws.org/Vol-3740/paper-34.pdf'
citation: 'Chowdhury, Md. Sajid Alam, Anik Shanto, Mostak Mahmud Chowdhury, Hasan Murad and Udoy Das. “Fired_from_NLP at CheckThat! 2024: Estimating the Check-Worthiness of Tweets Using a Fine-tuned Transformer-based Approach.” Conference and Labs of the Evaluation Forum (2024).'
---
Due to immense usage and dependence on web-based and social media platforms, we nowadays come across a lot of information but all of them are not true. Thus, it is important to verify a statement before believing it. Therefore, Checking the validity of a statement has become a core research topic in Natural Language Processing (NLP) in both low-resource and resource-enriched languages. The CheckThat! Lab at CLEF 2024 has organized a shared task named Check-worthiness estimation (Task 1) where three datasets have been provided in the Arabic, English, and Dutch languages to determine whether a claim in a tweet and/or transcriptions is worth fact-checking. To perform the task, we have utilized several machine learning, deep learning, and transformer-based models to check which model performs best on the given datasets. Among all of these models, our proposed CW-BERT model has ranked 7th, 10th, and 12th, scoring the F1 scores of 0.530, 0.543, and 0.745 in this task for the Arabic, English, and Dutch language respectively.